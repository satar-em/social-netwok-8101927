from __future__ import annotations

import re
import pandas as pd


NEG_KW = ["Ú©Ø´ØªÙ‡","Ù‚ØªÙ„","Ù…Ø±Ú¯","Ø§Ø¹Ø¯Ø§Ù…","Ø¨Ø§Ø²Ø¯Ø§Ø´Øª","Ø²Ù†Ø¯Ø§Ù†","Ø³Ø±Ú©ÙˆØ¨","Ø´Ù„ÛŒÚ©","Ú¯Ù„ÙˆÙ„Ù‡","Ø­Ù…Ù„Ù‡","Ø§Ù†ÙØ¬Ø§Ø±","ØªÙ‡Ø¯ÛŒØ¯","Ø¬Ù†Ú¯","Ù…Ø²Ø¯ÙˆØ±","Ø³ÙØ§Ú©","Ø®ÙˆÙ†","ÙˆØ­Ø´ÛŒ","Ø¢ØªØ´","ØªØ±ÙˆØ±","Ù…Ø¬Ø±ÙˆØ­","ÙØ§Ø¬Ø¹Ù‡"]
CONFLICT_KW = ["Ø§Ø¹ØªØ±Ø§Ø¶","Ø§Ø¹ØªØ±Ø§Ø¶Ø§Øª","Ù…Ø¹ØªØ±Ø¶","Ø³Ø±Ú©ÙˆØ¨","Ø¯Ø±Ú¯ÛŒØ±ÛŒ","Ø­Ù…Ù„Ù‡","Ø¬Ù†Ú¯","Ù…ÙˆØ´Ú©","Ø¹Ù…Ù„ÛŒØ§Øª","Ù†ÛŒØ±ÙˆÙ‡Ø§ÛŒ","ÛŒÚ¯Ø§Ù†","Ø³Ù¾Ø§Ù‡","Ù¾Ù„ÛŒØ³","Ø¨Ø³ÛŒØ¬","Ø§Ø³Ø±Ø§Ø¦ÛŒÙ„","Ø§Ø³Ø±Ø§ÛŒÛŒÙ„","ØºØ²Ù‡","Ø­Ù…Ø§Ø³","Ø­Ø²Ø¨ Ø§Ù„Ù„Ù‡","Ø­ÙˆØ«ÛŒ"]
IMPACT_KW = ["Ù‡Ø²Ø§Ø±","Ù…ÛŒÙ„ÛŒÙˆÙ†","Ú©Ø´ØªÙ‡","Ù…Ø¬Ø±ÙˆØ­","Ø¨Ø§Ø²Ø¯Ø§Ø´Øª","Ù‚Ø·Ø¹","Ø§ÛŒÙ†ØªØ±Ù†Øª","Ø¨ÛŒÙ…Ø§Ø±Ø³ØªØ§Ù†","Ø­Ù…Ù„Ù‡","Ø¢ØªØ´","Ø§Ù†ÙØ¬Ø§Ø±","ØªØ­Ø±ÛŒÙ…"]
SURPRISE_KW = ["Ø¹Ø¬ÛŒØ¨","ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡","Ù†Ø§Ú¯Ù‡Ø§Ù†ÛŒ","Ø´ÙˆÚ©","Ø¨Ø§ÙˆØ±Ù†Ú©Ø±Ø¯Ù†ÛŒ"]
HUMAN_KW = ["Ú©ÙˆØ¯Ú©","Ù…Ø§Ø¯Ø±","Ù¾Ø¯Ø±","Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡","Ø¯Ø§Ù†Ø´Ø¬Ùˆ","Ù¾Ø±Ø³ØªØ§Ø±","Ø¨ÛŒÙ…Ø§Ø±Ø³ØªØ§Ù†","Ø²Ù†","Ø¯Ø®ØªØ±","Ù¾Ø³Ø±","Ú©Ø§Ø±Ú¯Ø±","Ù…Ø¹Ù„Ù…","Ø²Ù†Ø¯Ú¯ÛŒ","Ú¯Ø±ÛŒÙ‡","Ù‚Ø±Ø¨Ø§Ù†ÛŒ"]
VISUAL_KW = ["ÙˆÛŒØ¯ÛŒÙˆ","ÙÛŒÙ„Ù…","ØªØµÙˆÛŒØ±","Ø¹Ú©Ø³","Ú©Ù„ÛŒÙ¾","ðŸ“¹","ðŸŽ¥","ðŸ“·"]
SHARE_KW = ["Ø±ÛŒØªÙˆØ¦ÛŒØª","Ø±ÛŒØªÙˆÛŒÛŒØª","RT","ÙÙˆØ±ÙˆØ§Ø±Ø¯","Ù¾Ø®Ø´ Ú©Ù†ÛŒØ¯","Ø¨Ù‡ Ø§Ø´ØªØ±Ø§Ú©","share","Ø¨Ø§Ø²Ù†Ø´Ø±","Ø§Ù†ØªØ´Ø§Ø± Ø¯Ù‡ÛŒØ¯","Ù„Ø·ÙØ§ Ù…Ù†ØªØ´Ø±","Ù¾Ø®Ø´"]

ELITE_KW = [
    "Ø®Ø§Ù…Ù†Ù‡","Ø±Ø¦ÛŒØ³ÛŒ","Ù¾Ø²Ø´Ú©ÛŒØ§Ù†","ØªØ±Ø§Ù…Ù¾","Ø¨Ø§ÛŒØ¯Ù†","Ù†ØªØ§Ù†ÛŒØ§Ù‡Ùˆ","Ø²Ù„Ù†Ø³Ú©ÛŒ","Ù¾ÙˆØªÛŒÙ†",
    "Ø±Ø¶Ø§ Ù¾Ù‡Ù„ÙˆÛŒ","Ø´Ø§Ù‡Ø²Ø§Ø¯Ù‡","Ù¾Ù‡Ù„ÙˆÛŒ","Ø³Ù¾Ø§Ù‡","Ù…Ø¬Ù„Ø³","Ø³Ø§Ø²Ù…Ø§Ù† Ù…Ù„Ù„","UN","EU","Ø¢Ù…Ø±ÛŒÚ©Ø§","Ø§ÛŒØ±Ø§Ù†","Ø§Ø³Ø±Ø§Ø¦ÛŒÙ„","Ø§Ø³Ø±Ø§ÛŒÛŒÙ„"
]

IR_CITIES = ["ØªÙ‡Ø±Ø§Ù†","Ù…Ø´Ù‡Ø¯","Ø§ØµÙÙ‡Ø§Ù†","Ø´ÛŒØ±Ø§Ø²","ØªØ¨Ø±ÛŒØ²","Ú©Ø±Ø¬","Ø§Ù‡ÙˆØ§Ø²","Ù‚Ù…","Ú©Ø±Ù…Ø§Ù†Ø´Ø§Ù‡","Ø§ÛŒÙ„Ø§Ù…","Ø²Ø§Ù‡Ø¯Ø§Ù†","Ø³Ù†Ù†Ø¯Ø¬","Ø§Ø±ÙˆÙ…ÛŒÙ‡",
             "Ø±Ø´Øª","Ú©Ø±Ù…Ø§Ù†","ÛŒØ²Ø¯","Ø¨ÙˆØ´Ù‡Ø±","Ø¨Ù†Ø¯Ø±Ø¹Ø¨Ø§Ø³","Ù‡Ù…Ø¯Ø§Ù†","Ø³Ø§Ø±ÛŒ","Ú¯Ø±Ú¯Ø§Ù†","Ù‚Ø²ÙˆÛŒÙ†","Ø§Ø±Ø§Ú©","Ø§Ø±Ø¯Ø¨ÛŒÙ„","Ø¨ÛŒØ±Ø¬Ù†Ø¯",
             "Ø®Ø±Ù…","Ø®Ø±Ù… Ø¢Ø¨Ø§Ø¯","Ø¨Ø¬Ù†ÙˆØ±Ø¯","Ø´Ù‡Ø±Ú©Ø±Ø¯","Ú©ÛŒØ´","Ù‚Ø´Ù…","Ù…Ø§Ù‡Ø´Ù‡Ø±","Ø¢Ø¨Ø§Ø¯Ø§Ù†","Ú©Ø§Ø²Ø±ÙˆÙ†","Ù…Ø±ÛŒÙˆØ§Ù†","Ø³Ù‚Ø²","Ø¨ÙˆÚ©Ø§Ù†","Ú©Ø§Ø´Ø§Ù†"]


def contains_any(text: str, keywords) -> bool:
    if not isinstance(text, str):
        return False
    return any(k in text for k in keywords)


_num_pattern = re.compile(r"\d|[Û°-Û¹]")


def news_values_from_row(row: pd.Series) -> dict:
    text = str(row.get("text", ""))
    sentiment = str(row.get("sentiment", "")).strip()

    return {
        "timeliness": True,
        "negativity": (sentiment == "Ù…Ù†ÙÛŒ") or contains_any(text, NEG_KW),
        "conflict": contains_any(text, CONFLICT_KW),
        "impact_magnitude": contains_any(text, IMPACT_KW) or bool(_num_pattern.search(text)),
        "elite_prominence": contains_any(text, ELITE_KW),
        "proximity": contains_any(text, IR_CITIES) or ("Ø§ÛŒØ±Ø§Ù†" in text),
        "surprise": contains_any(text, SURPRISE_KW),
        "human_interest": contains_any(text, HUMAN_KW),
        "visuals": contains_any(text, VISUAL_KW),
        "shareability": contains_any(text, SHARE_KW) or ("
    }


def add_news_values(df: pd.DataFrame) -> pd.DataFrame:
    df2 = df.reset_index(drop=True).copy()
    tags = df2.apply(news_values_from_row, axis=1, result_type="expand")
    return pd.concat([df2, tags], axis=1)
