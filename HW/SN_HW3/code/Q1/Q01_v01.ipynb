{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# SN_HW3\n",
    "\n",
    "```Networks``` folder should be near this notebook"
   ],
   "id": "be33295ddeed8f24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports & Setup",
   "id": "9ccfcedd05ae1fa2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T19:12:49.086228100Z",
     "start_time": "2026-01-07T19:12:49.043292900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List, Set, Optional\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "# RANDOM_SEED = 42\n",
    "# random.seed(RANDOM_SEED)\n",
    "# np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "BASE_DIR = Path(\".\").resolve()\n",
    "\n",
    "OUTPUT_DIR = BASE_DIR / \"outputs\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "NETWORKS_DIR = BASE_DIR / \"Networks\"\n"
   ],
   "id": "96b459d2f37475ad",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Q1",
   "id": "4d6033b83b518430"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Locate",
   "id": "f2adf09847ddedb9"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-07T19:12:49.150233200Z",
     "start_time": "2026-01-07T19:12:49.106221100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PART_A_DIR = NETWORKS_DIR / \"Part_A\"\n",
    "OUTPUT_DIR_Q1=OUTPUT_DIR/'Q1'\n",
    "OUTPUT_DIR_Q1.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Using NETWORKS_DIR =\", NETWORKS_DIR)\n",
    "print(\"Outputs will be written to:\", OUTPUT_DIR_Q1)"
   ],
   "id": "50fcf1855e047c39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NETWORKS_DIR = C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\Networks\n",
      "Outputs will be written to: C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Helper Functions",
   "id": "72f119ced845a84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T19:12:49.176744700Z",
     "start_time": "2026-01-07T19:12:49.153509700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_signed_undirected_csv(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    cols = [c.strip().lower() for c in df.columns]\n",
    "    df.columns = cols\n",
    "    if len(df.columns) < 3:\n",
    "        raise ValueError(f\"Expected >=3 columns in {path}, got {df.columns}\")\n",
    "    df = df.rename(columns={df.columns[0]: \"u\", df.columns[1]: \"v\", df.columns[2]: \"sign\"})\n",
    "    return df[[\"u\", \"v\", \"sign\"]].copy()\n",
    "\n",
    "def read_directed_edge_csv(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    cols = [c.strip().lower() for c in df.columns]\n",
    "    df.columns = cols\n",
    "    if len(df.columns) < 2:\n",
    "        raise ValueError(f\"Expected >=2 columns in {path}, got {df.columns}\")\n",
    "    df = df.rename(columns={df.columns[0]: \"src\", df.columns[1]: \"dst\"})\n",
    "    return df[[\"src\", \"dst\"]].copy()\n",
    "\n",
    "def ensure_int_nodes(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        out[c] = out[c].astype(int)\n",
    "    return out\n",
    "\n",
    "def build_signed_graph_undirected(df_edges: pd.DataFrame, include_zero: bool=False) -> nx.Graph:\n",
    "    G = nx.Graph()\n",
    "    for u, v, s in df_edges[[\"u\",\"v\",\"sign\"]].itertuples(index=False):\n",
    "        u = int(u); v = int(v); s = int(s)\n",
    "        if (not include_zero) and s == 0:\n",
    "            continue\n",
    "        G.add_edge(u, v, sign=s)\n",
    "    return G\n",
    "\n",
    "def save_df(df: pd.DataFrame, path: Path) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"***file saved*** => {path}\")\n",
    "\n",
    "def zip_outputs(folder: Path, zip_path: Path) -> None:\n",
    "    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        for file_path in folder.rglob(\"*\"):\n",
    "            if file_path.is_file():\n",
    "                zf.write(file_path, file_path.relative_to(folder.parent))\n",
    "\n",
    "def deterministic_spring_layout(G: nx.Graph, seed: int=42):\n",
    "    return nx.spring_layout(G, seed=seed)\n",
    "\n",
    "def plot_signed_clusters(\n",
    "    G: nx.Graph,\n",
    "    node_cluster: Dict[int,int],\n",
    "    out_path: Path,\n",
    "    title: str = \"\",\n",
    "    seed: int = 42\n",
    ") -> None:\n",
    "    pos = deterministic_spring_layout(G, seed=seed)\n",
    "    clusters = sorted(set(node_cluster.values()))\n",
    "    cluster_to_idx = {c:i for i,c in enumerate(clusters)}\n",
    "    node_colors = [cluster_to_idx[node_cluster[n]] for n in G.nodes()]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, cmap=plt.cm.tab20, node_size=250, alpha=0.9)\n",
    "\n",
    "    pos_edges = [(u,v) for u,v,d in G.edges(data=True) if d.get(\"sign\", 1) == 1]\n",
    "    neg_edges = [(u,v) for u,v,d in G.edges(data=True) if d.get(\"sign\", 1) == -1]\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=pos_edges, alpha=0.4)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=neg_edges, style=\"dashed\", alpha=0.4)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=200)\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    print(f\"***file saved*** => {out_path}\")\n"
   ],
   "id": "2cfb5066814f3603",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 1 — Sign prediction in a balanced signed graph",
   "id": "deede7cb7db50855"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T19:12:49.212916100Z",
     "start_time": "2026-01-07T19:12:49.178756200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "part1_path = PART_A_DIR / \"1\" / \"balanced_graph.csv\"\n",
    "df1 = read_signed_undirected_csv(part1_path)\n",
    "df1 = ensure_int_nodes(df1, [\"u\",\"v\"])\n",
    "df1[\"sign\"] = df1[\"sign\"].astype(int)\n",
    "\n",
    "df_known = df1[df1[\"sign\"] != 0].copy()\n",
    "df_unknown = df1[df1[\"sign\"] == 0].copy()\n",
    "\n",
    "G_known = build_signed_graph_undirected(df_known, include_zero=False)\n",
    "\n",
    "labels: Dict[int,int] = {}\n",
    "\n",
    "def assign_labels_via_bfs(G: nx.Graph) -> Dict[int,int]:\n",
    "    labels: Dict[int,int] = {}\n",
    "    for start in G.nodes():\n",
    "        if start in labels:\n",
    "            continue\n",
    "        labels[start] = 0\n",
    "        queue = [start]\n",
    "        while queue:\n",
    "            u = queue.pop(0)\n",
    "            for v, data in G[u].items():\n",
    "                s = int(data.get(\"sign\", 1))\n",
    "                desired = labels[u] ^ (1 if s == -1 else 0)\n",
    "                # print(f's={s},labels[u]={labels[u]} ,(1 if s == -1 else 0)={(1 if s == -1 else 0)},desired={desired}')\n",
    "                if v not in labels:\n",
    "                    labels[v] = desired\n",
    "                    queue.append(v)\n",
    "                else:\n",
    "                    if labels[v] != desired:\n",
    "                        raise ValueError(\n",
    "                            f\"Inconsistent constraints encountered at edge ({u},{v}) with sign {s}.\"\n",
    "                        )\n",
    "    return labels\n",
    "\n",
    "labels = assign_labels_via_bfs(G_known)\n",
    "\n",
    "all_nodes = set(df1[\"u\"]).union(set(df1[\"v\"]))\n",
    "for n in all_nodes:\n",
    "    if int(n) not in labels:\n",
    "        labels[int(n)] = 0\n",
    "\n",
    "pred_rows = []\n",
    "for u, v in df_unknown[[\"u\",\"v\"]].itertuples(index=False):\n",
    "    u = int(u); v = int(v)\n",
    "    pred = 1 if labels[u] == labels[v] else -1\n",
    "    pred_rows.append((u, v, pred))\n",
    "\n",
    "df_pred = pd.DataFrame(pred_rows, columns=[\"u\",\"v\",\"predicted_sign\"])\n",
    "\n",
    "df_partition = pd.DataFrame(sorted(labels.items()), columns=[\"node\",\"group\"])\n",
    "save_df(df_partition, OUTPUT_DIR_Q1 / \"q1_part1_partition.csv\")\n",
    "save_df(df_pred, OUTPUT_DIR_Q1 / \"q1_part1_predicted_unknown_edges.csv\")\n",
    "\n",
    "print(\"Part 1 done.\")\n",
    "print(\"number of node:\",len(all_nodes) ,\"Known edges:\", len(df_known), \"Unknown edges:\", len(df_unknown))\n",
    "print(f\"group'0'={(df_partition['group']==0).sum()} , group'1'={(df_partition['group']==1).sum()}\")\n",
    "print(f\"predicted_sign'1'={(df_pred['predicted_sign']==1).sum()} , predicted_sign'-1'={(df_pred['predicted_sign']==-1).sum()}\")"
   ],
   "id": "17a1c6f84d4b3ce7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part1_partition.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part1_predicted_unknown_edges.csv\n",
      "Part 1 done.\n",
      "number of node: 50 Known edges: 135 Unknown edges: 89\n",
      "group'0'=32 , group'1'=18\n",
      "predicted_sign'1'=40 , predicted_sign'-1'=49\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 2 — Balance test via Super-node reduction",
   "id": "3ac4f4c0b4280779"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T19:12:49.296866600Z",
     "start_time": "2026-01-07T19:12:49.215917400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "part2_dir = PART_A_DIR / \"2\"\n",
    "network_files = sorted(part2_dir.glob(\"network_*.csv\"))\n",
    "\n",
    "def union_find_components(edges: List[Tuple[int,int]], nodes: Set[int]) -> Dict[int,int]:\n",
    "    parent = {n:n for n in nodes}\n",
    "    rank = {n:0 for n in nodes}\n",
    "\n",
    "    def find(x):\n",
    "        while parent[x] != x:\n",
    "            parent[x] = parent[parent[x]]\n",
    "            x = parent[x]\n",
    "        return x\n",
    "\n",
    "    def union(a,b):\n",
    "        ra, rb = find(a), find(b)\n",
    "        if ra == rb:\n",
    "            return\n",
    "        if rank[ra] < rank[rb]:\n",
    "            parent[ra] = rb\n",
    "        elif rank[ra] > rank[rb]:\n",
    "            parent[rb] = ra\n",
    "        else:\n",
    "            parent[rb] = ra\n",
    "            rank[ra] += 1\n",
    "\n",
    "    for u,v in edges:\n",
    "        union(u,v)\n",
    "\n",
    "    roots = {find(n) for n in nodes}\n",
    "    root_to_sid = {r:i for i,r in enumerate(sorted(roots))}\n",
    "    node_to_sid = {n: root_to_sid[find(n)] for n in nodes}\n",
    "    return node_to_sid\n",
    "\n",
    "def supernode_balance_test(df: pd.DataFrame):\n",
    "    df = ensure_int_nodes(df, [\"u\",\"v\"])\n",
    "    df[\"sign\"] = df[\"sign\"].astype(int)\n",
    "    nodes = set(df[\"u\"]).union(set(df[\"v\"]))\n",
    "\n",
    "    pos_edges = [(int(u),int(v)) for u,v,s in df[[\"u\",\"v\",\"sign\"]].itertuples(index=False) if int(s)==1]\n",
    "    neg_edges = [(int(u),int(v)) for u,v,s in df[[\"u\",\"v\",\"sign\"]].itertuples(index=False) if int(s)==-1]\n",
    "\n",
    "    node_to_super = union_find_components(pos_edges, nodes)\n",
    "\n",
    "    for u,v in neg_edges:\n",
    "        if node_to_super[u] == node_to_super[v]:\n",
    "            return {\n",
    "                \"balanced\": False,\n",
    "                \"reason\": \"negative_edge_inside_supernode\",\n",
    "                \"example\": (u,v),\n",
    "                \"node_to_super\": node_to_super,\n",
    "                \"reduced_graph\": None,\n",
    "                \"odd_cycle\": None\n",
    "            }\n",
    "\n",
    "    H = nx.Graph()\n",
    "    for sid in set(node_to_super.values()):\n",
    "        H.add_node(sid)\n",
    "    for u,v in neg_edges:\n",
    "        su, sv = node_to_super[u], node_to_super[v]\n",
    "        if su != sv:\n",
    "            H.add_edge(su, sv, sign=-1)\n",
    "\n",
    "    if not nx.is_bipartite(H):\n",
    "        odd = None\n",
    "        try:\n",
    "            cycles = nx.cycle_basis(H)\n",
    "            for c in cycles:\n",
    "                if len(c) % 2 == 1:\n",
    "                    odd = c\n",
    "                    break\n",
    "        except Exception:\n",
    "            odd = None\n",
    "        return {\n",
    "            \"balanced\": False,\n",
    "            \"reason\": \"reduced_graph_not_bipartite\",\n",
    "            \"example\": None,\n",
    "            \"node_to_super\": node_to_super,\n",
    "            \"reduced_graph\": H,\n",
    "            \"odd_cycle\": odd\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"balanced\": True,\n",
    "        \"reason\": \"ok\",\n",
    "        \"example\": None,\n",
    "        \"node_to_super\": node_to_super,\n",
    "        \"reduced_graph\": H,\n",
    "        \"odd_cycle\": None\n",
    "    }\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "for f in network_files:\n",
    "    df = read_signed_undirected_csv(f)\n",
    "    result = supernode_balance_test(df)\n",
    "    name = f.stem\n",
    "\n",
    "    assign_df = pd.DataFrame(sorted(result[\"node_to_super\"].items()), columns=[\"node\",\"supernode\"])\n",
    "    save_df(assign_df, OUTPUT_DIR_Q1 / f\"q1_part2_supernode_assignment_{name}.csv\")\n",
    "\n",
    "    if result[\"reduced_graph\"] is not None:\n",
    "        H = result[\"reduced_graph\"]\n",
    "        red_df = pd.DataFrame([(u,v) for u,v in H.edges()], columns=[\"super_u\",\"super_v\"])\n",
    "    else:\n",
    "        red_df = pd.DataFrame(columns=[\"super_u\",\"super_v\"])\n",
    "    save_df(red_df, OUTPUT_DIR_Q1 / f\"q1_part2_reduced_graph_edges_{name}.csv\")\n",
    "\n",
    "    nodes = set(df[\"u\"]).union(set(df[\"v\"]))\n",
    "    summary_rows.append({\n",
    "        \"network\": name,\n",
    "        \"balanced\": bool(result[\"balanced\"]),\n",
    "        \"reason\": result[\"reason\"],\n",
    "        \"example_edge\": str(result.get(\"example\")),\n",
    "        \"odd_cycle_supernodes\": str(result.get(\"odd_cycle\")),\n",
    "        \"num_nodes\": int(len(nodes)),\n",
    "        \"num_edges\": int(len(df)),\n",
    "        \"num_supernodes\": int(len(set(result[\"node_to_super\"].values()))),\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_rows)\n",
    "\n",
    "save_df(df_summary, OUTPUT_DIR_Q1 / \"q1_part2_balance_summary.csv\")\n",
    "\n",
    "print(\"Part 2 done. Summary saved to outputs/q1_part2_balance_summary.csv\")"
   ],
   "id": "906e7cd7ff9105a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_supernode_assignment_network_a.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_reduced_graph_edges_network_a.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_supernode_assignment_network_b.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_reduced_graph_edges_network_b.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_supernode_assignment_network_c.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_reduced_graph_edges_network_c.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_supernode_assignment_network_d.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_reduced_graph_edges_network_d.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_supernode_assignment_network_e.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_reduced_graph_edges_network_e.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_supernode_assignment_network_f.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_reduced_graph_edges_network_f.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_supernode_assignment_network_g.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_reduced_graph_edges_network_g.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_supernode_assignment_network_h.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_reduced_graph_edges_network_h.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part2_balance_summary.csv\n",
      "Part 2 done. Summary saved to outputs/q1_part2_balance_summary.csv\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 3 — Clusterability (Weak balance) and visualization",
   "id": "981c5967531f68fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T19:12:50.606738300Z",
     "start_time": "2026-01-07T19:12:49.300643500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "part3_dir = PART_A_DIR / \"3\"\n",
    "files3 = sorted(part3_dir.glob(\"network_*.csv\"))\n",
    "\n",
    "def positive_components_clustering(df: pd.DataFrame):\n",
    "    df = ensure_int_nodes(df, [\"u\",\"v\"])\n",
    "    df[\"sign\"] = df[\"sign\"].astype(int)\n",
    "    nodes = set(df[\"u\"]).union(set(df[\"v\"]))\n",
    "\n",
    "    Gpos = nx.Graph()\n",
    "    Gpos.add_nodes_from(nodes)\n",
    "    for u,v,s in df[[\"u\",\"v\",\"sign\"]].itertuples(index=False):\n",
    "        if int(s) == 1:\n",
    "            Gpos.add_edge(int(u), int(v))\n",
    "\n",
    "    comps = list(nx.connected_components(Gpos))\n",
    "    node_to_cluster = {}\n",
    "    for cid, comp in enumerate(comps):\n",
    "        for n in comp:\n",
    "            node_to_cluster[int(n)] = cid\n",
    "\n",
    "    for u,v,s in df[[\"u\",\"v\",\"sign\"]].itertuples(index=False):\n",
    "        if int(s) == -1 and node_to_cluster[int(u)] == node_to_cluster[int(v)]:\n",
    "            return node_to_cluster, False, (int(u),int(v))\n",
    "\n",
    "    return node_to_cluster, True, None\n",
    "\n",
    "summary3 = []\n",
    "\n",
    "for f in files3:\n",
    "    name = f.stem\n",
    "    df = read_signed_undirected_csv(f)\n",
    "    node_to_cluster, ok, example = positive_components_clustering(df)\n",
    "\n",
    "    assign_df = pd.DataFrame(sorted(node_to_cluster.items()), columns=[\"node\",\"cluster\"])\n",
    "    save_df(assign_df, OUTPUT_DIR_Q1 / f\"q1_part3_cluster_assignment_{name}.csv\")\n",
    "\n",
    "    sizes = pd.Series(list(node_to_cluster.values())).value_counts().sort_index()\n",
    "    size_list = [int(sizes[i]) for i in sizes.index]\n",
    "\n",
    "    G = build_signed_graph_undirected(df, include_zero=False)\n",
    "    fig_path = OUTPUT_DIR_Q1 / f\"q1_part3_clusters_{name}.png\"\n",
    "    plot_signed_clusters(G, node_to_cluster, fig_path, title=f\"{name} clusters (positive components)\")\n",
    "\n",
    "    summary3.append({\n",
    "        \"network\": name,\n",
    "        \"weakly_balanced_check\": bool(ok),\n",
    "        \"violating_negative_edge\": str(example),\n",
    "        \"num_clusters\": int(len(set(node_to_cluster.values()))),\n",
    "        \"cluster_sizes\": str(size_list),\n",
    "        \"figure_path\": str(fig_path.relative_to(BASE_DIR))\n",
    "    })\n",
    "\n",
    "df3 = pd.DataFrame(summary3)\n",
    "save_df(df3, OUTPUT_DIR_Q1 / \"q1_part3_clusterability_summary.csv\")\n",
    "\n",
    "print(\"Part 3 done. Summary saved to outputs/q1_part3_clusterability_summary.csv\")"
   ],
   "id": "88ab89766a4f7cb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part3_cluster_assignment_network_a.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part3_clusters_network_a.png\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part3_cluster_assignment_network_b.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part3_clusters_network_b.png\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part3_cluster_assignment_network_c.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part3_clusters_network_c.png\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part3_cluster_assignment_network_d.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part3_clusters_network_d.png\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part3_cluster_assignment_network_e.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part3_clusters_network_e.png\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part3_clusterability_summary.csv\n",
      "Part 3 done. Summary saved to outputs/q1_part3_clusterability_summary.csv\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 4 — Line Index for a 4-cluster signed network (random + heuristic)",
   "id": "db970c7bb2d74b81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T19:12:50.898462400Z",
     "start_time": "2026-01-07T19:12:50.663882300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "part4_path = PART_A_DIR / \"4\" / \"network_line_index.csv\"\n",
    "df4 = read_signed_undirected_csv(part4_path)\n",
    "df4 = ensure_int_nodes(df4, [\"u\",\"v\"])\n",
    "df4[\"sign\"] = df4[\"sign\"].astype(int)\n",
    "\n",
    "nodes4 = sorted(set(df4[\"u\"]).union(set(df4[\"v\"])))\n",
    "k = 4\n",
    "alpha = 0.5\n",
    "\n",
    "def compute_PN_line_index(df: pd.DataFrame, assignment: Dict[int,int], alpha: float = 0.5) -> Tuple[int,int,float]:\n",
    "    P = 0\n",
    "    N = 0\n",
    "    for u,v,s in df[[\"u\",\"v\",\"sign\"]].itertuples(index=False):\n",
    "        u = int(u); v = int(v); s = int(s)\n",
    "        cu, cv = assignment[u], assignment[v]\n",
    "        if s == 1 and cu != cv:\n",
    "            P += 1\n",
    "        elif s == -1 and cu == cv:\n",
    "            N += 1\n",
    "    LI = alpha * P + (1 - alpha) * N\n",
    "    return P, N, float(LI)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "assign_random = {int(n): int(rng.integers(0, k)) for n in nodes4}\n",
    "P_r, N_r, LI_r = compute_PN_line_index(df4, assign_random, alpha=alpha)\n",
    "\n",
    "save_df(pd.DataFrame(sorted(assign_random.items()), columns=[\"node\",\"cluster\"]),\n",
    "        OUTPUT_DIR_Q1 / \"q1_part4_random_assignment.csv\")\n",
    "\n",
    "adj = {int(n): [] for n in nodes4}\n",
    "for u,v,s in df4[[\"u\",\"v\",\"sign\"]].itertuples(index=False):\n",
    "    u=int(u); v=int(v); s=int(s)\n",
    "    adj[u].append((v,s))\n",
    "    adj[v].append((u,s))\n",
    "\n",
    "def cost_P_plus_N(df: pd.DataFrame, assignment: Dict[int,int]) -> int:\n",
    "    P, N, _ = compute_PN_line_index(df, assignment, alpha=0.5)\n",
    "    return P + N\n",
    "\n",
    "def delta_move(node: int, new_c: int, assignment: Dict[int,int]) -> int:\n",
    "    old_c = assignment[node]\n",
    "    if new_c == old_c:\n",
    "        return 0\n",
    "    delta = 0\n",
    "    for nei, s in adj[node]:\n",
    "        c_nei = assignment[nei]\n",
    "        cur_bad = 1 if (s == 1 and old_c != c_nei) or (s == -1 and old_c == c_nei) else 0\n",
    "        new_bad = 1 if (s == 1 and new_c != c_nei) or (s == -1 and new_c == c_nei) else 0\n",
    "        delta += (new_bad - cur_bad)\n",
    "    return delta\n",
    "\n",
    "def local_search(initial: Dict[int,int], max_iters: int = 20000) -> Tuple[Dict[int,int], List[int]]:\n",
    "    assign = dict(initial)\n",
    "    history = [cost_P_plus_N(df4, assign)]\n",
    "    improved = True\n",
    "    it = 0\n",
    "    while improved and it < max_iters:\n",
    "        improved = False\n",
    "        it += 1\n",
    "        for n in nodes4:\n",
    "            best_delta = 0\n",
    "            best_c = assign[n]\n",
    "            for c in range(k):\n",
    "                d = delta_move(n, c, assign)\n",
    "                if d < best_delta:\n",
    "                    best_delta = d\n",
    "                    best_c = c\n",
    "            if best_delta < 0:\n",
    "                assign[n] = best_c\n",
    "                history.append(history[-1] + best_delta)\n",
    "                improved = True\n",
    "    return assign, history\n",
    "\n",
    "best_assign = None\n",
    "best_cost = None\n",
    "best_history = None\n",
    "\n",
    "num_restarts = 20\n",
    "rng2 = np.random.default_rng(123)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    init = {int(n): int(rng2.integers(0, k)) for n in nodes4}\n",
    "    sol, hist = local_search(init)\n",
    "    c = hist[-1]\n",
    "    if best_cost is None or c < best_cost:\n",
    "        best_cost = c\n",
    "        best_assign = sol\n",
    "        best_history = hist\n",
    "\n",
    "P_h, N_h, LI_h = compute_PN_line_index(df4, best_assign, alpha=alpha)\n",
    "\n",
    "save_df(pd.DataFrame(sorted(best_assign.items()), columns=[\"node\",\"cluster\"]),\n",
    "        OUTPUT_DIR_Q1 / \"q1_part4_heuristic_assignment.csv\")\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(best_history)\n",
    "plt.xlabel(\"Improvement step\")\n",
    "plt.ylabel(\"P+N (misplaced edges)\")\n",
    "plt.title(\"Local search history (best restart)\")\n",
    "plt.tight_layout()\n",
    "history_path = OUTPUT_DIR_Q1 / \"q1_part4_local_search_history.png\"\n",
    "plt.savefig(history_path, dpi=200)\n",
    "print(f\"***file saved*** => {history_path}\")\n",
    "# plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"Part 4 done.\")\n",
    "print(\"Random: P,N,LI=\", P_r, N_r, LI_r)\n",
    "print(\"Heuristic best: P,N,LI=\", P_h, N_h, LI_h)\n"
   ],
   "id": "7ec53e6d3bac199e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part4_random_assignment.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part4_heuristic_assignment.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part4_local_search_history.png\n",
      "Part 4 done.\n",
      "Random: P,N,LI= 82 17 49.5\n",
      "Heuristic best: P,N,LI= 0 0 0.0\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 5 — Transitivity in a directed network",
   "id": "5ba389d9ca26cb06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T19:12:51.468986800Z",
     "start_time": "2026-01-07T19:12:50.900559300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "part5_path = PART_A_DIR / \"5\" / \"network_transitivity.csv\"\n",
    "df5 = read_directed_edge_csv(part5_path)\n",
    "df5 = ensure_int_nodes(df5, [\"src\",\"dst\"])\n",
    "\n",
    "Gd = nx.DiGraph()\n",
    "for s,t in df5[[\"src\",\"dst\"]].itertuples(index=False):\n",
    "    Gd.add_edge(int(s), int(t))\n",
    "\n",
    "edges_set: Set[Tuple[int,int]] = set(Gd.edges())\n",
    "\n",
    "two_step_total = 0\n",
    "transitive_triples = 0\n",
    "missing_edges_2step: Set[Tuple[int,int]] = set()\n",
    "\n",
    "out_neighbors = {u: list(Gd.successors(u)) for u in Gd.nodes()}\n",
    "\n",
    "for i in Gd.nodes():\n",
    "    for j in out_neighbors.get(i, []):\n",
    "        for k in out_neighbors.get(j, []):\n",
    "            two_step_total += 1\n",
    "            if (i, k) in edges_set:\n",
    "                transitive_triples += 1\n",
    "            else:\n",
    "                missing_edges_2step.add((i, k))\n",
    "\n",
    "transitivity_ratio = (transitive_triples / two_step_total) if two_step_total > 0 else float(\"nan\")\n",
    "\n",
    "closure = nx.transitive_closure(Gd)\n",
    "closure_edges = set(closure.edges())\n",
    "edges_to_add_full = sorted(list(closure_edges - edges_set))\n",
    "\n",
    "missing_2step_df = pd.DataFrame(sorted(list(missing_edges_2step)), columns=[\"src\",\"dst\"])\n",
    "save_df(missing_2step_df, OUTPUT_DIR_Q1 / \"q1_part5_missing_edges_for_2step_paths.csv\")\n",
    "\n",
    "add_df = pd.DataFrame(edges_to_add_full, columns=[\"src\",\"dst\"])\n",
    "save_df(add_df, OUTPUT_DIR_Q1 / \"q1_part5_edges_to_add_for_transitivity.csv\")\n",
    "\n",
    "print(\"Part 5 done.\")\n",
    "print(\"Gd.nodes():\",len(Gd.nodes()))\n",
    "print(\"2-step paths:\", two_step_total)\n",
    "print(\"transitive triples:\", transitive_triples)\n",
    "print(\"ratio:\", transitivity_ratio)\n",
    "print(\"edges to add for full transitivity:\", len(edges_to_add_full))"
   ],
   "id": "ad461406f2913e09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part5_missing_edges_for_2step_paths.csv\n",
      "***file saved*** => C:\\programing\\University of Tehran\\social-netwok-8101927\\HW\\SN_HW3\\code\\Q1\\outputs\\Q1\\q1_part5_edges_to_add_for_transitivity.csv\n",
      "Part 5 done.\n",
      "Gd.nodes(): 200\n",
      "2-step paths: 3299\n",
      "transitive triples: 70\n",
      "ratio: 0.021218551076083662\n",
      "edges to add for full transitivity: 38186\n"
     ]
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
